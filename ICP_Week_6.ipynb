{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d8MPsdf1XvsZ",
        "outputId": "cb684257-f104-4d44-c682-7a8d67bb1397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.4090 - loss: 1.7721 - val_accuracy: 0.9088 - val_loss: 0.3143\n",
            "Epoch 2/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9092 - loss: 0.2996 - val_accuracy: 0.9462 - val_loss: 0.1842\n",
            "Epoch 3/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9443 - loss: 0.1795 - val_accuracy: 0.9558 - val_loss: 0.1437\n",
            "Epoch 4/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9609 - loss: 0.1304 - val_accuracy: 0.9616 - val_loss: 0.1274\n",
            "Epoch 5/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9665 - loss: 0.1094 - val_accuracy: 0.9627 - val_loss: 0.1223\n",
            "Epoch 6/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9720 - loss: 0.0867 - val_accuracy: 0.9660 - val_loss: 0.1126\n",
            "Epoch 7/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.9782 - loss: 0.0707 - val_accuracy: 0.9688 - val_loss: 0.1076\n",
            "Epoch 8/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9818 - loss: 0.0586 - val_accuracy: 0.9655 - val_loss: 0.1164\n",
            "Epoch 9/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9854 - loss: 0.0481 - val_accuracy: 0.9689 - val_loss: 0.1035\n",
            "Epoch 10/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9868 - loss: 0.0430 - val_accuracy: 0.9715 - val_loss: 0.0962\n",
            "Epoch 11/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.9899 - loss: 0.0330 - val_accuracy: 0.9736 - val_loss: 0.0954\n",
            "Epoch 12/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9919 - loss: 0.0286 - val_accuracy: 0.9718 - val_loss: 0.1046\n",
            "Epoch 13/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9910 - loss: 0.0289 - val_accuracy: 0.9728 - val_loss: 0.0986\n",
            "Epoch 14/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0193 - val_accuracy: 0.9750 - val_loss: 0.0989\n",
            "Epoch 15/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9947 - loss: 0.0174 - val_accuracy: 0.9741 - val_loss: 0.1083\n",
            "Epoch 16/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9943 - loss: 0.0170 - val_accuracy: 0.9693 - val_loss: 0.1262\n",
            "Epoch 17/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9956 - loss: 0.0156 - val_accuracy: 0.9734 - val_loss: 0.1198\n",
            "Epoch 18/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9964 - loss: 0.0119 - val_accuracy: 0.9737 - val_loss: 0.1100\n",
            "Epoch 19/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0093 - val_accuracy: 0.9751 - val_loss: 0.1054\n",
            "Epoch 20/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0067 - val_accuracy: 0.9724 - val_loss: 0.1205\n",
            "Epoch 21/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9977 - loss: 0.0079 - val_accuracy: 0.9748 - val_loss: 0.1159\n",
            "Epoch 22/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9978 - loss: 0.0075 - val_accuracy: 0.9748 - val_loss: 0.1180\n",
            "Epoch 23/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9989 - loss: 0.0046 - val_accuracy: 0.9776 - val_loss: 0.1068\n",
            "Epoch 24/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9999 - loss: 0.0012 - val_accuracy: 0.9785 - val_loss: 0.1090\n",
            "Epoch 25/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1377e-04 - val_accuracy: 0.9786 - val_loss: 0.1117\n",
            "Epoch 26/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2084e-04 - val_accuracy: 0.9784 - val_loss: 0.1137\n",
            "Epoch 27/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7717e-04 - val_accuracy: 0.9784 - val_loss: 0.1161\n",
            "Epoch 28/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1058e-04 - val_accuracy: 0.9784 - val_loss: 0.1174\n",
            "Epoch 29/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9086e-04 - val_accuracy: 0.9785 - val_loss: 0.1190\n",
            "Epoch 30/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5610e-04 - val_accuracy: 0.9786 - val_loss: 0.1195\n",
            "Epoch 31/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.5167e-04 - val_accuracy: 0.9787 - val_loss: 0.1210\n",
            "Epoch 32/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3051e-04 - val_accuracy: 0.9785 - val_loss: 0.1221\n",
            "Epoch 33/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.3296e-04 - val_accuracy: 0.9779 - val_loss: 0.1229\n",
            "Epoch 34/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.2235e-04 - val_accuracy: 0.9784 - val_loss: 0.1239\n",
            "Epoch 35/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.1019e-04 - val_accuracy: 0.9783 - val_loss: 0.1249\n",
            "Epoch 36/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.0181e-04 - val_accuracy: 0.9785 - val_loss: 0.1258\n",
            "Epoch 37/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9646e-05 - val_accuracy: 0.9782 - val_loss: 0.1262\n",
            "Epoch 38/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.9612e-05 - val_accuracy: 0.9782 - val_loss: 0.1272\n",
            "Epoch 39/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 8.8580e-05 - val_accuracy: 0.9787 - val_loss: 0.1282\n",
            "Epoch 40/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.6385e-05 - val_accuracy: 0.9785 - val_loss: 0.1285\n",
            "Epoch 41/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.3371e-05 - val_accuracy: 0.9782 - val_loss: 0.1293\n",
            "Epoch 42/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.2828e-05 - val_accuracy: 0.9787 - val_loss: 0.1300\n",
            "Epoch 43/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 7.0976e-05 - val_accuracy: 0.9783 - val_loss: 0.1305\n",
            "Epoch 44/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.4916e-05 - val_accuracy: 0.9783 - val_loss: 0.1311\n",
            "Epoch 45/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.5244e-05 - val_accuracy: 0.9784 - val_loss: 0.1315\n",
            "Epoch 46/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 6.1747e-05 - val_accuracy: 0.9785 - val_loss: 0.1320\n",
            "Epoch 47/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.6303e-05 - val_accuracy: 0.9788 - val_loss: 0.1324\n",
            "Epoch 48/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.4389e-05 - val_accuracy: 0.9784 - val_loss: 0.1329\n",
            "Epoch 49/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.3578e-05 - val_accuracy: 0.9787 - val_loss: 0.1335\n",
            "Epoch 50/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 5.1827e-05 - val_accuracy: 0.9787 - val_loss: 0.1339\n",
            "Epoch 51/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9248e-05 - val_accuracy: 0.9790 - val_loss: 0.1346\n",
            "Epoch 52/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.9845e-05 - val_accuracy: 0.9787 - val_loss: 0.1346\n",
            "Epoch 53/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.7346e-05 - val_accuracy: 0.9788 - val_loss: 0.1355\n",
            "Epoch 54/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.6869e-05 - val_accuracy: 0.9786 - val_loss: 0.1358\n",
            "Epoch 55/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2985e-05 - val_accuracy: 0.9785 - val_loss: 0.1362\n",
            "Epoch 56/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.5055e-05 - val_accuracy: 0.9787 - val_loss: 0.1367\n",
            "Epoch 57/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.3930e-05 - val_accuracy: 0.9784 - val_loss: 0.1369\n",
            "Epoch 58/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.8926e-05 - val_accuracy: 0.9786 - val_loss: 0.1373\n",
            "Epoch 59/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0978e-05 - val_accuracy: 0.9783 - val_loss: 0.1378\n",
            "Epoch 60/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.0814e-05 - val_accuracy: 0.9784 - val_loss: 0.1381\n",
            "Epoch 61/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 4.2353e-05 - val_accuracy: 0.9785 - val_loss: 0.1383\n",
            "Epoch 62/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.7490e-05 - val_accuracy: 0.9787 - val_loss: 0.1388\n",
            "Epoch 63/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.6146e-05 - val_accuracy: 0.9787 - val_loss: 0.1393\n",
            "Epoch 64/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3955e-05 - val_accuracy: 0.9787 - val_loss: 0.1396\n",
            "Epoch 65/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.2227e-05 - val_accuracy: 0.9786 - val_loss: 0.1399\n",
            "Epoch 66/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.3813e-05 - val_accuracy: 0.9787 - val_loss: 0.1402\n",
            "Epoch 67/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.4854e-05 - val_accuracy: 0.9785 - val_loss: 0.1405\n",
            "Epoch 68/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.1374e-05 - val_accuracy: 0.9787 - val_loss: 0.1408\n",
            "Epoch 69/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0434e-05 - val_accuracy: 0.9786 - val_loss: 0.1412\n",
            "Epoch 70/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 3.0549e-05 - val_accuracy: 0.9787 - val_loss: 0.1411\n",
            "Epoch 71/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7540e-05 - val_accuracy: 0.9785 - val_loss: 0.1417\n",
            "Epoch 72/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9129e-05 - val_accuracy: 0.9787 - val_loss: 0.1419\n",
            "Epoch 73/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8690e-05 - val_accuracy: 0.9786 - val_loss: 0.1421\n",
            "Epoch 74/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7732e-05 - val_accuracy: 0.9786 - val_loss: 0.1424\n",
            "Epoch 75/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.9438e-05 - val_accuracy: 0.9787 - val_loss: 0.1428\n",
            "Epoch 76/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.8710e-05 - val_accuracy: 0.9785 - val_loss: 0.1431\n",
            "Epoch 77/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.7563e-05 - val_accuracy: 0.9787 - val_loss: 0.1433\n",
            "Epoch 78/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5856e-05 - val_accuracy: 0.9787 - val_loss: 0.1435\n",
            "Epoch 79/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.6195e-05 - val_accuracy: 0.9784 - val_loss: 0.1438\n",
            "Epoch 80/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5689e-05 - val_accuracy: 0.9787 - val_loss: 0.1441\n",
            "Epoch 81/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.5203e-05 - val_accuracy: 0.9787 - val_loss: 0.1442\n",
            "Epoch 82/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4626e-05 - val_accuracy: 0.9787 - val_loss: 0.1446\n",
            "Epoch 83/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.4993e-05 - val_accuracy: 0.9785 - val_loss: 0.1449\n",
            "Epoch 84/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3695e-05 - val_accuracy: 0.9786 - val_loss: 0.1452\n",
            "Epoch 85/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.3175e-05 - val_accuracy: 0.9786 - val_loss: 0.1455\n",
            "Epoch 86/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2446e-05 - val_accuracy: 0.9787 - val_loss: 0.1456\n",
            "Epoch 87/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2800e-05 - val_accuracy: 0.9787 - val_loss: 0.1459\n",
            "Epoch 88/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.2163e-05 - val_accuracy: 0.9786 - val_loss: 0.1460\n",
            "Epoch 89/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1402e-05 - val_accuracy: 0.9785 - val_loss: 0.1464\n",
            "Epoch 90/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1050e-05 - val_accuracy: 0.9787 - val_loss: 0.1466\n",
            "Epoch 91/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.1302e-05 - val_accuracy: 0.9786 - val_loss: 0.1467\n",
            "Epoch 92/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0086e-05 - val_accuracy: 0.9785 - val_loss: 0.1469\n",
            "Epoch 93/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9207e-05 - val_accuracy: 0.9785 - val_loss: 0.1471\n",
            "Epoch 94/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 2.0815e-05 - val_accuracy: 0.9785 - val_loss: 0.1473\n",
            "Epoch 95/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9053e-05 - val_accuracy: 0.9786 - val_loss: 0.1475\n",
            "Epoch 96/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9351e-05 - val_accuracy: 0.9785 - val_loss: 0.1477\n",
            "Epoch 97/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.9303e-05 - val_accuracy: 0.9786 - val_loss: 0.1479\n",
            "Epoch 98/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8914e-05 - val_accuracy: 0.9786 - val_loss: 0.1482\n",
            "Epoch 99/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.8262e-05 - val_accuracy: 0.9784 - val_loss: 0.1484\n",
            "Epoch 100/100\n",
            "\u001b[1m1500/1500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 1.0000 - loss: 1.7775e-05 - val_accuracy: 0.9784 - val_loss: 0.1486\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9765 - loss: 0.1478\n",
            "Test accuracy: 0.9794999957084656\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# Preprocess the data: normalize images and one-hot encode labels\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Build a Sequential model\n",
        "model = Sequential()\n",
        "\n",
        "# Flatten the input (28x28 images) into a vector of size 784\n",
        "model.add(Flatten(input_shape=(28, 28)))\n",
        "\n",
        "# Add a hidden layer with 128 neurons and ReLU activation\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(256, activation='tanh'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "\n",
        "\n",
        "# Add the output layer with 10 neurons (one for each class) and softmax activation\n",
        "model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model on the test data\n",
        "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
        "print(f'Test accuracy: {test_acc}')"
      ]
    }
  ]
}